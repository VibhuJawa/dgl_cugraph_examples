{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc964922-062e-425b-b916-645195d734d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42081bc4-59ae-4df6-8f93-0f7b5ba2517c",
   "metadata": {},
   "source": [
    "### E2E benchmarks currently: \n",
    "```\n",
    "69_619.04 samples/sec  DGL CUDA\n",
    "17_911 samples/sec  DGL CPU\n",
    "20387.86 samples/sec cuGRAPH \n",
    "(We should be able to 2x this when etypes can be directly set in cugraph Graph)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88c3168-d955-48a5-ab16-09dc05320bf6",
   "metadata": {},
   "source": [
    "## Setup Memory Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e97c3029-8b48-4dab-a68e-d87df92560c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import rmm\n",
    "\n",
    "rmm.reinitialize(pool_allocator=True,initial_pool_size=5e+9, maximum_pool_size=22e+9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700073a1-40f5-4146-b9f2-7584218431bb",
   "metadata": {},
   "source": [
    "# OBGN- Mag DataSet Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27079a5b-28b1-472d-9063-5ebbb4a2dffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/vjawa/miniconda3/envs/cugraph_dgl_dev_oct_5/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ogb.nodeproppred import DglNodePropPredDataset, Evaluator\n",
    "from dgl import AddReverse, Compose, ToSimple\n",
    "import dgl\n",
    "\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb549cf4-cbdd-4bf2-bec9-d9874f9e9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Local Imports from this folder\n",
    "from logger import Logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ca4e88-dc40-4dd5-be6a-94c114448992",
   "metadata": {},
   "source": [
    "## Step 1.a:  Load the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb972351-64d8-42ed-9d0e-2471529b2f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dgl_graph(paper_dim_to_load=10):\n",
    "    dataset = DglNodePropPredDataset(name=\"ogbn-mag\", root='/datasets/vjawa/gnn/')\n",
    "    split_idx = dataset.get_idx_split()\n",
    "    # graph: dgl graph object, label: torch tensor of shape (num_nodes, num_tasks)\n",
    "    g, labels = dataset[0]        \n",
    "    # Update to paper_dim_to_load to save on GPU memory for non distributed versions\n",
    "    # We need to clear g.ndata to do this\n",
    "    ndata = {k: v for k, v in g.ndata.items()}\n",
    "    g.ndata.clear()        \n",
    "    ndata['feat']['paper'] = ndata['feat']['paper'][:,:paper_dim_to_load]\n",
    "    g.ndata.update(ndata)\n",
    "    \n",
    "    labels = labels[\"paper\"].flatten()\n",
    "    transform = Compose([ToSimple(), AddReverse()])\n",
    "    g = transform(g)\n",
    "    print(\"Loaded graph: {}\".format(g))\n",
    "    return g, labels, dataset.num_classes, split_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b00ffcf2-7797-4c07-b438-c9c3ebc1722a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph: Graph(num_nodes={'author': 1134649, 'field_of_study': 59965, 'institution': 8740, 'paper': 736389},\n",
      "      num_edges={('author', 'affiliated_with', 'institution'): 1043998, ('author', 'writes', 'paper'): 7145660, ('field_of_study', 'rev_has_topic', 'paper'): 7505078, ('institution', 'rev_affiliated_with', 'author'): 1043998, ('paper', 'cites', 'paper'): 10832542, ('paper', 'has_topic', 'field_of_study'): 7505078, ('paper', 'rev_writes', 'author'): 7145660},\n",
      "      metagraph=[('author', 'institution', 'affiliated_with'), ('author', 'paper', 'writes'), ('institution', 'author', 'rev_affiliated_with'), ('paper', 'paper', 'cites'), ('paper', 'field_of_study', 'has_topic'), ('paper', 'author', 'rev_writes'), ('field_of_study', 'paper', 'rev_has_topic')])\n"
     ]
    }
   ],
   "source": [
    "load_d_feature = 10\n",
    "device = 'cuda'\n",
    "\n",
    "g, labels, num_classes, split_idx = load_dgl_graph(load_d_feature)\n",
    "assert g.ndata['feat']['paper'].shape[1] == load_d_feature\n",
    "\n",
    "\n",
    "g = g.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe6db6-7053-4c21-894b-129f670bd1a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1.b Convert Graph from DGL Graph to cugraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8141aea5-1905-413e-9d6f-32ae120513be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Local Imports from this folder\n",
    "from dgl_cugraph_conversion_utils import add_edges, add_nodes, add_ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80de1683-9110-4f7c-9e65-3b30198721da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Nodes\n",
      "Added Edges\n",
      "Added ndata\n"
     ]
    }
   ],
   "source": [
    "def graphstore_from_hetrograph(gs, g):\n",
    "    num_nodes_dict = {ntype: g.num_nodes(ntype) for ntype in g.ntypes}\n",
    "    add_nodes(gs, g, num_nodes_dict)\n",
    "    print(\"Added Nodes\")\n",
    "    add_edges(gs, g, num_nodes_dict)\n",
    "    print(\"Added Edges\")\n",
    "    add_ndata(gs, g, num_nodes_dict)\n",
    "    print(\"Added ndata\")\n",
    "    #TODO: \n",
    "    # add_edata\n",
    "\n",
    "gs = dgl.contrib.cugraph.CuGraphStorage(idtype=g.idtype)\n",
    "graphstore_from_hetrograph(gs, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aa6207-9024-4711-8c3a-18e83e30ed52",
   "metadata": {},
   "source": [
    "#### Verify Similar Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "089af299-fa77-44f1-a38e-993ce967d699",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing Similar Structure\n",
    "from dgl_cugraph_conversion_utils import assert_same_num_nodes, assert_same_num_edges\n",
    "gs.num_edges(etype='affiliated_with')==g.num_edges(etype='affiliated_with')\n",
    "assert_same_num_edges(gs, g)\n",
    "assert_same_num_nodes(gs, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e35091-30c0-4974-b8a4-57dcc8d8dbf5",
   "metadata": {},
   "source": [
    "### Update g to graphstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04981d68-139d-4ff6-909c-248422d854c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gs\n",
    "del gs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de4610-f617-4e9e-9e3f-8dae6700f2d3",
   "metadata": {},
   "source": [
    "## Step 1.c Initiate Sampler and Train Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6668781b-17fc-44ca-b88e-2a722b3cae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Run only on 200_000 samples to test the pipeline\n",
    "n_samples = 100_000\n",
    "subset_split_idx = {'train': {k: v[:n_samples].to(device) for k,v in split_idx['train'].items()},\n",
    "                   'valid' : {k: v[:n_samples].to(device) for k,v in split_idx['valid'].items()},\n",
    "                    'test' : {k: v[:n_samples].to(device) for k,v in split_idx['test'].items()},\n",
    "                   }\n",
    "\n",
    "\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([25, 20], prefetch_node_feats={'paper':['feat']})\n",
    "train_loader = dgl.dataloading.DataLoader(\n",
    "    g,\n",
    "    #split_idx,\n",
    "    subset_split_idx[\"train\"],\n",
    "    sampler,\n",
    "    batch_size=8192,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ba696e-13ca-4a04-bd0b-30e44b401808",
   "metadata": {},
   "source": [
    "## Step 2. Initate a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59bc993-1494-4e47-abb4-d4e1d8c6ac65",
   "metadata": {},
   "source": [
    "###  Traing HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5262d52-6e52-4315-905e-262d93a5914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import  rel_graph_embed,extract_embed\n",
    "from model import EntityClassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90eaf286-7787-4dd7-9aab-b0f4df3abcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nruns = 2\n",
    "logger = Logger(nruns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d091d050-20b2-47c4-9807-5f6425229187",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_index = torch.IntTensor([0]).to(device)\n",
    "feat_shape = g.get_node_storage(key='feat', ntype='paper').fetch(first_index, device=device).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0b2daf1-5e3b-40fa-802c-52ee00ae36e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of embedding parameters: 12033540\n",
      "Number of model parameters: 254388\n"
     ]
    }
   ],
   "source": [
    "embedding_shape = feat_shape\n",
    "embed_layer = rel_graph_embed(g, embedding_shape).to(device)\n",
    "model = EntityClassify(g, embedding_shape, num_classes).to(device)\n",
    "\n",
    "print(\n",
    "    f\"Number of embedding parameters: {sum(p.numel() for p in embed_layer.parameters())}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of model parameters: {sum(p.numel() for p in model.parameters())}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23032b3-1268-44e0-816f-f9049c5479bc",
   "metadata": {},
   "source": [
    "## Benchmark Training Loop\n",
    "```\n",
    "Toal Time = 6.8 s\n",
    "Forward pass= 1.25 s (18% time)\n",
    "DataLoader/Sampling = 5.52 s (80% time) \n",
    "\n",
    "In Data Loading : \n",
    "4.9 s in sample_neighbours \n",
    "3.94s _get_edgeid_type_d (This should go away soon) \n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cbf6ec6-2326-42b4-974c-ed9fcea217dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sampling_behavior_benchmark(g, seed_nodes,labels, node_embed, train_loader):\n",
    "#     category = \"paper\"\n",
    "#     all_params = itertools.chain(model.parameters(), embed_layer.parameters())\n",
    "#     optimizer = th.optim.Adam(all_params, lr=0.01)\n",
    "\n",
    "        \n",
    "#     for input_nodes, seeds, blocks in train_loader:\n",
    "#         seeds = seeds[category]\n",
    "#         emb = extract_embed(node_embed, input_nodes)\n",
    "#         feat = blocks[0].srcdata['feat']['paper']\n",
    "#         # Add the batch's raw \"paper\" features\n",
    "#         emb.update(\n",
    "#             {\"paper\": feat}\n",
    "#             #{\"paper\": g.ndata[\"feat\"][\"paper\"][input_nodes[\"paper\"]]}\n",
    "#         )\n",
    "\n",
    "#         emb = {k: e.to(device) for k, e in emb.items()}\n",
    "#         lbl = labels[seeds].to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         logits = model(emb, blocks)[category]\n",
    "\n",
    "#         y_hat = logits.log_softmax(dim=-1)\n",
    "#         loss = F.nll_loss(y_hat, lbl)\n",
    "#     return None\n",
    "# %snakeviz sampling_behavior_benchmark(g, subset_split_idx['train'],labels,embed_layer, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def3bbad-7947-4c33-8056-2f512e3a1a6d",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a1d2ff9-788a-4b1b-b873-781250805317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    g,\n",
    "    model,\n",
    "    node_embed,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    split_idx,\n",
    "    labels,\n",
    "    logger,\n",
    "    device,\n",
    "    run,\n",
    "):\n",
    "    print(\"start training...\")\n",
    "    category = \"paper\"\n",
    "    for epoch in range(5):\n",
    "        num_train = split_idx[\"train\"][category].shape[0]\n",
    "        pbar = tqdm(total=num_train)\n",
    "        pbar.set_description(f\"Epoch {epoch:02d}\")\n",
    "        model.train()\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        for input_nodes, seeds, blocks in train_loader:\n",
    "            blocks = [blk.to(device) for blk in blocks]\n",
    "            seeds = seeds[\n",
    "                category\n",
    "            ]  # we only predict the nodes with type \"category\"\n",
    "            batch_size = seeds.shape[0]\n",
    "\n",
    "            emb = extract_embed(node_embed, input_nodes)\n",
    "            \n",
    "            feat = blocks[0].srcdata['feat']['paper']\n",
    "            #label = subgs[-1].dstdata['label']\n",
    "    \n",
    "            # Add the batch's raw \"paper\" features\n",
    "            emb.update(\n",
    "                {\"paper\": feat}\n",
    "                #{\"paper\": g.ndata[\"feat\"][\"paper\"][input_nodes[\"paper\"]]}\n",
    "            )\n",
    "\n",
    "            emb = {k: e.to(device) for k, e in emb.items()}\n",
    "            lbl = labels[seeds].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(emb, blocks)[category]\n",
    "\n",
    "            y_hat = logits.log_softmax(dim=-1)\n",
    "            loss = F.nll_loss(y_hat, lbl)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * batch_size\n",
    "            pbar.update(batch_size)\n",
    "            \n",
    "        pbar.close()\n",
    "        loss = total_loss / num_train\n",
    "\n",
    "    result = test(g, model, node_embed, labels, device, split_idx)\n",
    "    logger.add_result(run, result)\n",
    "    train_acc, valid_acc, test_acc = result\n",
    "    print(\n",
    "        f\"Run: {run + 1:02d}, \"\n",
    "        f\"Epoch: {epoch +1 :02d}, \"\n",
    "        f\"Loss: {loss:.4f}, \"\n",
    "        f\"Train: {100 * train_acc:.2f}%, \"\n",
    "        f\"Valid: {100 * valid_acc:.2f}%, \"\n",
    "        f\"Test: {100 * test_acc:.2f}%\"\n",
    "    )\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "@th.no_grad()\n",
    "def test(g, model, node_embed, y_true, device, split_idx):\n",
    "    model.eval()\n",
    "    category = \"paper\"\n",
    "    evaluator = Evaluator(name=\"ogbn-mag\")\n",
    "    \n",
    "    #TODO: Fix memory issues  (VJAWA)\n",
    "    # 2 GNN layers\n",
    "    # Possible memory leak\n",
    "    # sampler = dgl.dataloading.MultiLayerFullNeighborSampler(2,  prefetch_node_feats={'paper':['feat']})\n",
    "    sampler = dgl.dataloading.MultiLayerNeighborSampler([25, 20], prefetch_node_feats={'paper':['feat']})\n",
    "    \n",
    "    loader = dgl.dataloading.DataLoader(\n",
    "        g,\n",
    "        {\"paper\": th.arange(g.num_nodes(\"paper\")).to(device)},\n",
    "        sampler,\n",
    "        batch_size=16384,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        device = device,\n",
    "    )\n",
    "\n",
    "    pbar = tqdm(total=y_true.size(0))\n",
    "    pbar.set_description(f\"Inference\")\n",
    "\n",
    "    y_hats = list()\n",
    "    \n",
    "    for input_nodes, seeds, blocks in loader:\n",
    "        blocks = [blk.to(device) for blk in blocks]\n",
    "        seeds = seeds[\n",
    "            category\n",
    "        ]  # we only predict the nodes with type \"category\"\n",
    "        batch_size = seeds.shape[0]\n",
    "\n",
    "        emb = extract_embed(node_embed, input_nodes)\n",
    "        # Get the batch's raw \"paper\" features\n",
    "        \n",
    "        ## prefetch_feat\n",
    "        feat = blocks[0].srcdata['feat']['paper']\n",
    "        emb.update({\"paper\": feat})\n",
    "        emb = {k: e.to(device) for k, e in emb.items()}\n",
    "\n",
    "        logits = model(emb, blocks)[category]\n",
    "        y_hat = logits.log_softmax(dim=-1).argmax(dim=1, keepdims=True)\n",
    "        y_hats.append(y_hat.cpu())\n",
    "\n",
    "        pbar.update(batch_size)\n",
    "        \n",
    "        del input_nodes, seeds, blocks\n",
    "        del feat, emb\n",
    "\n",
    "        \n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    y_pred = th.cat(y_hats, dim=0)\n",
    "    y_pred_rows = y_pred.shape[0]\n",
    "    \n",
    "    y_true = th.unsqueeze(y_true[:y_pred_rows], 1)\n",
    "    \n",
    "    \n",
    "    train_split_idx = split_idx[\"train\"][\"paper\"]\n",
    "    valid_split_idx = split_idx[\"valid\"][\"paper\"]\n",
    "    test_split_idx =  split_idx[\"test\"][\"paper\"]\n",
    "    \n",
    "    ### I only want to calculate over the rows i had\n",
    "    \n",
    "\n",
    "    train_acc = evaluator.eval(\n",
    "        {\n",
    "            \"y_true\": y_true[train_split_idx],\n",
    "            \"y_pred\": y_pred[train_split_idx],\n",
    "        }\n",
    "    )[\"acc\"]\n",
    "    valid_acc = evaluator.eval(\n",
    "        {\n",
    "            \"y_true\": y_true[valid_split_idx],\n",
    "            \"y_pred\": y_pred[valid_split_idx],\n",
    "        }\n",
    "    )[\"acc\"]\n",
    "    test_acc = evaluator.eval(\n",
    "        {\n",
    "            \"y_true\": y_true[test_split_idx],\n",
    "            \"y_pred\": y_pred[test_split_idx],\n",
    "        }\n",
    "    )[\"acc\"]\n",
    "\n",
    "    return train_acc, valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17859c07-c453-4761-beec-c797b3e8a9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dgl.contrib.cugraph.cugraph_storage.CuGraphStorage"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b968645-81ea-4f74-8841-60e7e67d1be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 00: 100%|██████████| 100000/100000 [00:05<00:00, 19603.93it/s]\n",
      "Epoch 01: 100%|██████████| 100000/100000 [00:04<00:00, 20359.54it/s]\n",
      "Epoch 02: 100%|██████████| 100000/100000 [00:05<00:00, 19754.76it/s]\n",
      "Epoch 03: 100%|██████████| 100000/100000 [00:04<00:00, 20591.25it/s]\n",
      "Epoch 04: 100%|██████████| 100000/100000 [00:04<00:00, 20061.01it/s]\n",
      "Inference: 100%|██████████| 736389/736389 [00:16<00:00, 44165.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 01, Epoch: 05, Loss: 1.3529, Train: 83.33%, Valid: 30.59%, Test: 30.54%\n",
      "Run 01:\n",
      "Highest Train: 83.33\n",
      "Highest Valid: 30.59\n",
      "  Final Train: 83.33\n",
      "Final Test: 30.54\n",
      "start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 00: 100%|██████████| 100000/100000 [00:05<00:00, 19414.25it/s]\n",
      "Epoch 01: 100%|██████████| 100000/100000 [00:05<00:00, 19177.87it/s]\n",
      "Epoch 02: 100%|██████████| 100000/100000 [00:05<00:00, 19336.42it/s]\n",
      "Epoch 03: 100%|██████████| 100000/100000 [00:04<00:00, 20605.24it/s]\n",
      "Epoch 04: 100%|██████████| 100000/100000 [00:04<00:00, 20020.21it/s]\n",
      "Inference: 100%|██████████| 736389/736389 [00:16<00:00, 44958.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 02, Epoch: 05, Loss: 1.4598, Train: 79.96%, Valid: 30.50%, Test: 30.73%\n",
      "Run 02:\n",
      "Highest Train: 79.96\n",
      "Highest Valid: 30.50\n",
      "  Final Train: 79.96\n",
      "Final Test: 30.73\n",
      "Final performance: \n",
      "All runs:\n",
      "Highest Train: 81.64 ± 2.38\n",
      "Highest Valid: 30.54 ± 0.06\n",
      "  Final Train: 81.64 ± 2.38\n",
      "   Final Test: 30.64 ± 0.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for run in range(nruns):\n",
    "    embed_layer.reset_parameters()\n",
    "    model.reset_parameters()\n",
    "\n",
    "    # optimizer\n",
    "    all_params = itertools.chain(\n",
    "        model.parameters(), embed_layer.parameters()\n",
    "    )\n",
    "    optimizer = th.optim.Adam(all_params, lr=0.01)\n",
    "\n",
    "    logger = train(\n",
    "        g,\n",
    "        model,\n",
    "        embed_layer,\n",
    "        optimizer,\n",
    "        train_loader,\n",
    "        subset_split_idx,\n",
    "        #TODO: Change to split_idx,\n",
    "        labels,\n",
    "        logger,\n",
    "        device,\n",
    "        run,\n",
    "    )\n",
    "    logger.print_statistics(run)\n",
    "print(\"Final performance: \")\n",
    "logger.print_statistics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
